
# Log Classification With Hybrid Classification Framework

This project implements a hybrid log classification system, combining three complementary approaches to handle varying levels of complexity in log patterns. The classification methods ensure flexibility and effectiveness in processing predictable, complex, and poorly-labeled data patterns.

---

## Classification Approaches

1. **Regular Expression (Regex)**:
   - Handles the most simplified and predictable patterns.
   - Useful for patterns that are easily captured using predefined rules.

2. **Sentence Transformer + Logistic Regression**:
   - Manages complex patterns when there is sufficient training data.
   - Utilizes embeddings generated by Sentence Transformers and applies Logistic Regression as the classification layer.

3. **LLM (Large Language Models)**:
   - Used for handling complex patterns when sufficient labeled training data is not available.
   - Provides a fallback or complementary approach to the other methods.

![architecture](https://github.com/TammaTarunTeja/hybrid_log_classification_pipeline/blob/main/arch.png)

---

## Folder Structure

1. **`training/`**:
   - Contains the code for training models using Sentence Transformer and Logistic Regression.
   - Includes the code for regex-based classification.

2. **`models/`**:
   - Stores the saved models, including Sentence Transformer embeddings and the Logistic Regression model.

3. **`resources/`**:
   - This folder contains resource files such as test CSV files, output files, images, etc.

4. **Root Directory**:
   - Contains the FastAPI server code (`server.py`).

5. **Structure**:
   ```bash
   HYBRID_LOG_CLASSIFICATION_SYSTEM/
   ├── __pycache__/
   ├── .venv/
   ├── saved_models/
   │   └── lr_model.joblib
   ├── tranning/
   │   ├── cluster_logs.txt
   │   ├── hybrid_report.ipynb
   │   ├── process_data.ipynb
   │   └── tranning_logs.csv
   ├── .env
   ├── .gitignore
   ├── .python-version
   ├── classified_logs_output.csv
   ├── classifier.py
   ├── main.py
   ├── process_with_bert.py
   ├── process_with_llm.py
   ├── process_with_regex.py
   ├── pyproject.toml
   ├── README.md
   ├── requirements.txt
   ├── server.py
   └── uv.lock
---

## Setup Instructions

1. **Initialize UV **:
   ```bash
   uv init log_classification
   ```


2. **Install Dependencies**:
   Make sure you have Python installed on your system. Install the required Python libraries by running the following command:

   ```bash
   uv install -r requirements.txt
   ```

2. **Run the FastAPI Server**:
   To start the server, use the following command:

   ```bash
   uvicorn server:app --reload
   ```

   Once the server is running, you can access the API at:
   - `http://127.0.0.1:8000` (Main endpoint)

3. **Run Streamlit app**:
   To run streamlit app use following command :
   ```bash
   streamlit run main.py
   ```


---

## Usage

Upload a CSV file containing logs messages to the Streamlit app for classification. Ensure the file has the following columns:
- `source`
- `log_message`

The output will be a CSV file with an additional column `Predicted Label`, which represents the classified label for each log entry.You can download the predicted logs as CSV or EXCEL format



---
